%! Author = julianmour
%! Date = 01/05/2023


\section{Future Research Objectives}
In light of the preliminary work, we aim to further explore our ideas in the following directions:
\begin{itemize}
    \item Generalizing to networks over a large range of differences: We aim to extend our approach for networks that have a wider range of differences, for example changes over different layers and large value differences. This requires to extend our algorithm to automatically identify the differences.
    %\item Applying our algorithm to networks trained on databases other than MNIST.
    \item Generalizing the space of dependencies: Our current research focuses on identifying linear constraints. However, some differences between networks are captured by non-linear constraints. We aim at identifying such constraints and overapproximate them with linear constraints with as little loss in precision as possible. %Finding more constraints between the networks. As the preliminary results section presented, pruning the search space using constraints between the networks, significantly reduces the execution time. Therefore, we hypothesize that expanding the pruning of the search space could further decrease execution times.
    \item Identifying optimization hints using numerical optimization. Previous work~\cite{VHAGAR} has relied on numerical optimization to prune the MILP's search space. We expect that a similar approach is applicable to our setting. %These are partial assignments to the MIPâ€™s variables. It is used for guiding towards the optimal solution. It reduces execution times and enhances the scalability of the system.
\end{itemize}
