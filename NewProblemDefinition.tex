\documentclass[11pt]{article}
\usepackage[a4paper, portrait, margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{caption}
\usepackage[labelformat=simple]{subcaption}    %%Adding option to remove parenthesis
\renewcommand{\thesubfigure}{\normalsize Figure \thefigure. (\alph{subfigure}):}
% \usepackage{subcaption}
% \usepackage{subcaption}
%\usepackage{dirtytalk}
\usepackage{cjhebrew}
\usepackage{float}
\usepackage{eldar_report}
% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
% \newcommand\norm[1]{\lVert#1\rVert}
\newcommand\normx[1]{\Vert#1\Vert}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{lifetime}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{comment}
\usepackage{array}
\usepackage{float}
\newcommand{\Dana}[1]{\textcolor{purple}{\bf Dana: #1}}
\newcommand{\Neta}[1]{\textcolor{purple}{\bf Neta: #1}}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{cleveref}
\usepackage{amsthm}
\newtheorem{definition}{Definition}
\newtheorem{claim}{Claim}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xspace}

\newcommand{\D}{\mathcal{D}\xspace}
\newcommand{\Dp}{\mathcal{D}^p\xspace}
\newcommand{\phiin}{\phi_{\text{in}}\xspace}
\newcommand{\phidep}{\phi_{\text{dep}}\xspace}
\newcommand{\fp}{f_p\xspace}
\newcommand{\Ie}{I_\varepsilon\xspace}
\usepackage{algorithm}
\usepackage{algpseudocode}
\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}

\begin{document}
\section{Introduction}
The success of deep neural networks (DNNs) has led to deployment in mobile assistants, autonomous
vehicles, smart cameras, and IoT devices. In many such applications, low latency,
high availability, and strong privacy guarantees are critical. For example, 
voice assistants must detect wake words locally to ensure responsiveness
\cite{chen2014small,he2019streaming}, and autonomous vehicles require on-board perception models to react in real time, since relying solely on cloud connectivity could introduce
dangerous delays~\cite{richards2025edge,janai2020computer}.
At the same time, cloud-based models remain essential for handling complex queries
requiring large memory and compute resources \cite{computeinmemory2024,wolters2024memory}.

While large models achieve state-of-the-art accuracy, their resource demands
make them impractical for direct deployment on mobile or IoT hardware
\cite{han2015deep,howard2017mobilenets}. 
Quantization addresses this limitation by reducing the numerical
precision of weights and activations \cite{hubara2017quantized,gholami2021survey}.
Quantized neural networks (QNNs) enable efficient inference with smaller
memory footprints, lower energy consumption, and faster execution
\cite{krishnamoorthi2018quantizing}.

It introduces a trade-off:
compressed models often sacrifice accuracy compared to
their full-precision counterparts \cite{banner2019post} while providing efficient inference. This tension
motivates the design of cloud–edge hybrid frameworks, where a
quantized model operates locally for efficiency, and a large
full-precision model resides in the cloud to ensure accuracy and
scalability \cite{hao2024hybrid}.

\begin{comment}
\subsection*{Dequantization in Hybrid Cloud-Edge Systems}

Quantized Neural Networks (QNNs) are optimized for deployment on resource-constrained edge devices, such as smartphones, microcontrollers, smart cameras, and IoT sensors. These models utilize lower precision, typically 8-bit integers, to reduce memory usage and computational load, facilitating efficient inference on edge hardware \cite{turn0search1,turn0search4}. However, certain operations within neural networks, such as normalization, softmax, and specific post-processing steps, may not execute efficiently in low-precision arithmetic. These layers often require floating-point computations to maintain accuracy and stability \cite{turn0search4,turn0search6}. To address this, many QNN pipelines incorporate dequantization steps, where integer values are converted back to floating-point representations before processing these sensitive operations \cite{turn0search4}.

Edge devices performing QNN inference with dequantization steps require hardware that supports both low-precision integer operations and floating-point computations. Modern processors, such as Qualcomm's Snapdragon series, integrate specialized hardware accelerators capable of efficiently executing these mixed-precision operations. For instance, the Qualcomm AI Engine Direct SDK provides tools to construct and execute QNN graphs on Snapdragon chipsets, facilitating the deployment of quantized models with necessary dequantization steps \cite{turn0search2,turn0search15}.

Applications leveraging QNNs with dequantization steps on edge devices include real-time image recognition, natural language processing, and sensitive data identification. For example, the PQ-SDI model employs product quantization to compress high-dimensional embeddings, enabling efficient sensitive data identification on mobile edge devices \cite{turn0search13}. In hybrid cloud-edge systems, edge devices perform initial inference using quantized models, and when higher precision is required, dequantization is applied to ensure compatibility with cloud-based systems. This approach allows for efficient processing on the edge while maintaining the accuracy and computational demands of full-precision models in the cloud \cite{turn0search16}.

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Recent surveys \cite{satyanarayanan2017emergence,shi2016edge,mao2017survey} highlight
that hybrid edge–cloud deployments are becoming a cornerstone of
AI-enabled mobile systems. Teerapittayanon et
al.~\cite{teerapittayanon2017distributed} proposed distributed DNNs
where inference can terminate on-device for simple inputs, while complex
cases are escalated to the cloud. Kang et al.~\cite{kang2017neurosurgeon}
introduced Neurosurgeon, which partitions models between edge and
cloud to minimize latency and energy in classification tasks.
Li et al.~\cite{li2018edge} proposed routing policies that decide in
real time whether to use the local quantized model or the cloud model,
depending on network and device conditions. Ding et al. ~\cite{ding2024hybridllm} proposed an algorithm to assigns queries to the small or large model
based on the predicted query difficulty and the desired quality level in a cloud-edge framework.

This paradigm is already reflected in practice. Mobile assistants run
quantized keyword-spotting models locally, sending only confirmed speech
queries to the cloud for full processing \cite{alvarez2016energy}.
Smart cameras use local models for common object detection
\cite{cao2021edgecloud}, while relying on the cloud for
fine-grained recognition. In healthcare, wearable devices can detect
anomalies using lightweight quantized models \cite{xu2019edge}, with
cloud servers handling detailed analysis.
However, quantized neural networks (QNNs) remain vulnerable to adversarial perturbations, when even a small,
imperceptible changes to the input can cause a QNN to misclassify, much like
their full-precision counterparts~\cite{tramer2017space,lin2019defensive}.
Moreover, adversarial examples crafted for full-precision models often transfer to their quantized versions, indicating that quantization alone does
not provide robustness~\cite{zhao2019adversarial}.
It raises questions of robustness in cloud-edge framework ~\cite{hao2022diva}.

\begin{comment}
Adversarial inputs generated against the edge model can frequently transfer to
the cloud model, leading the entire system to misclassify perturbed inputs in
the same way it misclassifies them locally~\cite{tramer2017space,lin2019defensive}.
Such transferability undermines the intended complementarity of the two models,
as both become susceptible to the same adversarial examples.
\end{comment}


The formal verification of Quantized Neural Networks (QNNs) has received growing attention in recent years. Early works highlighted the inherent difficulty of verifying bit-precise QNNs, proving the task to be computationally hard, and proposed scalable heuristics to handle practical cases \cite{henzinger2021scalable}. Other approaches focused on exact verification by encoding QNNs into bit-vector or SMT formulations, thereby enabling automated checking of robustness properties at the quantized level \cite{sena2021smt, sena2021verifying}. Complementary research introduced Boolean encodings to formally reason about the correctness of QNNs with respect to desired safety properties \cite{kovasznai2023formal}.  
Building upon these foundations, more recent work has sought to improve efficiency and scalability. For example, \cite{huang2023towards} presents an integer linear programming (ILP) framework with soundness and completeness guarantees, enhanced by heuristic strategies. 

However, all of those works refer to local robustness of a single QNN network, with no consideration of the larger NN.
Kabaha and Drachsler-Cohen \cite{kabaha2025quantization} address the challenge of ensuring that the behavior of the QNN remains consistent with the original NN, thus bridging the gap between accuracy and efficiency in safety-critical applications, but did not addressed the challenges of proving robustness of the two.

In this work, we present a novel approach to verifying the robustness of hybrid cloud–edge systems against adversarial attacks, where a full-precision neural network resides in the cloud and its quantized counterpart operates on the edge, with each query being processed by only one of the two models.






\section{Problem Definition}
In this section, we define the problem we address.

\paragraph{Image classifiers}
An image classifier $N$ maps a two-dimensional image $x\in \mathbb{R}^{n \times m}$ to a score vector over the possible set of classes $C=\{1,\ldots,c_\text{max}\}$, that is:
$N: \mathbb{R}^{n \times m} \rightarrow {\mathbb{R}}^{|C|}$.
Given an input $x$, the classification $F$ assigns to $x$ is the class with the maximal score: $class(N(x))=argmax(N(x))$.

\paragraph{Perturbation}
Give an input $x$ and a perturbation vector $\epsilon'=(\epsilon_1,...,\epsilon_k)\in{\mathbb{R}}^{k}$, a perturbation is a function $f_P(x,\epsilon')$ defining how the input $x$ is perturbed. The perturbation vector $\epsilon'$ is confined in a given range $I_\epsilon$, denoted as $\epsilon'\in I_\epsilon$, where $I_\epsilon$ is a series of intervals, each bounding the possible values of each perturbation vector's entry: $\forall{k}$ $(\epsilon')_k\in (I_\epsilon)_k$.

\paragraph{Global robustness of a single network}
%In this thesis, we follow the global robustness property defined by~\cite{DECISIONBOUND}.
%Given a perturbation $P$ and its range $I_\epsilon$, a naive approach for global robustness is:
%$\forall{x}\forall{\epsilon'}\in{I_\epsilon}$  argmax($D(x)$) = argmax($f_P(x,\epsilon')$).
%However, this property is problematic because some inputs $x$ are too close to the classifier's decision boundaries and violate this property ~\cite{DECISIONBOUND}. As a result it is impossible to satisfy it for non-trivial classifier. Thus, this study focuses on inputs whose networks' confidence in the classification is high enough ~\cite{VHAGAR}:\\
This property focuses on the minimal \emph{class confidence} $\delta$ of a network $N$, for a given class $c$, such that \emph{every} input that the network classifies with a confidence over $\delta$ is robust with respect to a perturbation $P$. We next define it formally.
Given a classifier $N$, an input $x$ and a class $c\in{C}$, the class confidence of $N$ in $c$ is:
$$\mathcal{C}(x,c,N)=N(x)_{c}-max_{c'\ne c}(N(x)_{c'})$$
%For a single network, we define the property $\delta-Global Robustness$ as follows:\\
Given a classifier $N$, an input $x$, a class $c\in{C}$, a perturbation $P$, a range $I_\epsilon$ and a class confidence $\delta>0$, the classifier $N$ is $\delta$-globally robust for $c$ under $(P,I_\epsilon)$ if:\\
$$\forall{x}\forall{\epsilon'}\in{I_\epsilon}:    \mathcal{C}(x,c,N) \geq \delta \rightarrow argmax(N(x)) = argmax(N(f_P(x,\epsilon'))) $$
Intuitively, the classifier is robust with respect to $P$ for any input classified with confidence higher or equal to the minimal $\delta$. In practice, it is easier to compute the dual bound, i.e., the maximal globally non-robust bound. That is, the maximal class confidence $\delta$ that violates the constraint:
\begin{definition}[Maximal Non-Robust Bound (Vhagar)]\label{def:vhagar}
$$\max{\delta^{vhagar}(N)}, \texttt{ subject to } \exists{x}\exists{\epsilon'}\in{I_\epsilon}: \mathcal{C}(x,c,N) \geq \delta^{vhagar}(N) \rightarrow \mathcal{C}(f_P(x,\epsilon'),c,N)\leq 0$$
\end{definition}

\begin{comment}
\paragraph{Global robustness of a cloud-edge framework}
We define the robustness property $\delta_\text{cloud-edge}$ of a cloud-edge framework, with a large network $N_1$ with robustness $\delta^{vhagar}(N_1)$ in the cloud and a smaller network $N_2$ in the edge with robustness $\delta^{vhagar}(N_2)$ as:
$$\min{\{\delta^{vhagar}(N_1),\delta^{vhagar}(N_2)\}} \leq \delta_\text{cloud-edge} \leq \max{\{\delta^{vhagar}(N_1),\delta^{vhagar}(N_2)\}}$$
\end{comment}
\paragraph{Problem definition} 
We study the problem of \emph{proof transfer} between two similar networks. 
Specifically, we want to utilize the robustness of a single classifier in order to upper bound the minimally globally robust bound of a similar classifier. 
Technically, we upper bound the maximally globally robust bound.
%By doing so, we would be able to enhance the algorithm's scalability.
Formally, given two classifiers $N_1,N_2: \mathbb{R}^{n \times m} \rightarrow {\mathbb{R}}^{|C|}$, a class $c\in{C}$, a perturbation $P$ and its range $I_\epsilon$, our goal is to upper bound $\delta_2^\text{vhagar}$ as tightly as possibly by $\delta_1^\text{vhagar}$. To this end, our goal is to compute:
\begin{definition}[Maximal Network Difference]
\begin{equation}\label{eq:diff}
\min \delta_\text{diff}\text{ subject to } \forall x.\ |\mathcal{C}(x,c,N_2)-\mathcal{C}(x,c,N_1)|\leq \delta_\text{diff}
\end{equation}
\end{definition}
Given this value, if we prove that: 
\begin{definition}[Maximal Non-Robust Bound for Difference]
\begin{equation}\label{eq:vagdiff}
\max{\delta^\text{max\_diff}_1}, \texttt{ subject to } \exists{x}\exists{\epsilon'}\in{I_\epsilon}: \mathcal{C}(x,c,N_1) \geq \delta^\text{max\_diff}_1 \land \mathcal{C}(f_P(x,\epsilon'),c',N_1)\leq \delta_\text{diff}
\end{equation}
\end{definition}
Note that $\delta^\text{max\_diff}_1$ is an upper bound on the maximally globally robust bound of $N_1$, that is: $\delta^\text{max\_diff}_1\geq \delta^\text{vhagar}_1$ (this follows since Vhagar's second constraint is stronger: $\leq 0$). 
Let $\Delta$ be the computer precision level, then, $\delta^\text{min\_diff}_1 = \delta^\text{max\_diff}_1+\Delta$ is an upper bound on the minimally globally robust bound of $N_1$ (which is $\delta^\text{vhagar}_1+\Delta$).

Our proof transfer determines that $\delta^\text{max\_diff}_1+\delta_\text{diff}+\Delta$ is an upper bound on $\delta^\text{vhagar}_2$. Proof: For every $x$ whose confidence by $N_2$ is at least  $\delta^\text{max\_diff}_1+\delta_\text{diff}+\Delta$, by~\Cref{eq:diff}, $N_1$ classifies this input with confidence at least $\delta^\text{max\_diff}_1+\Delta$. By~\Cref{eq:vagdiff}, for every $\epsilon'\in I_\epsilon$, we have $\mathcal{C}(f_P(x,\epsilon'),c',N_1)>\delta_\text{diff}$. By~\Cref{eq:diff}, we can infer, $\mathcal{C}(f_P(x,\epsilon'),c',N_2)>0$.

\paragraph{Determining $\delta_\text{diff}$ for~\Cref{eq:vagdiff}:}
If we could compute~\Cref{eq:diff} and then verify properties for $N_1$ (with respect to~\Cref{eq:vagdiff}), this would be easy. However, this defeats the purpose of proof transfer, since first we have $N_1$, we prove properties for it, and only then we generate $N_2$. 
Thus, instead, %we wish to predict a useful upper bound on $\delta_\text{diff}$. While we could pick some large value, this would translate to higher values of $\delta_1^{opt}$, thus lowering the region of provable global robustness. Instead, 
we change Vhagar's constraint to be \emph{parametric} in $\delta_\text{diff}$. That is, we wish to find the smallest $A$ satisfying the following constraint:
\begin{equation}\label{eq:func}
\min A\text { subject to }\forall \delta_\text{diff} \forall{x}\forall{\epsilon'}\in{I_\epsilon}:    \delta_\text{diff}>0\land \mathcal{C}(x,c,N_1) \geq \delta_\text{diff} + A\rightarrow \mathcal{C}(f_P(x,\epsilon'),c',N_1)>\delta_\text{diff}
\end{equation}
This problem is feasible since a trivial solution to this constraint is assigning to $A$ the maximal confidence $N_1$ assigns for $c$ for any input. %However, this is not helpful. 
As usual, to find a value for $A$, we look at the dual problem, looking for the max $A$ violating this constraint
%can check if it satisfies the constraint by looking for a violation, that is looking for 
%\begin{equation}\label{eq:viol}
%\exists \delta_\text{diff} \exists {x}\exists{\epsilon'}\in{I_\epsilon}:   \delta_\text{diff}>0\land  \mathcal{C}(x,c,N) \geq  \delta_\text{diff} + A\land \mathcal{C}(f_P(x,\epsilon'),c',N_2)\leq \delta_\text{diff}
%\end{equation}
%We can look for the tightest bound by solving:
\begin{equation}\label{eq:ourproof}
 \max A \text{ subject to } \delta_\text{diff}>0\land \mathcal{C}(x,c,N_1) \geq \delta_\text{diff} + A\land \mathcal{C}(f_P(x,\epsilon'),c',N_1)\leq \delta_\text{diff}
 \end{equation}
  Then, if given a new network, we proved \Cref{eq:diff}, we can infer that:
  \begin{itemize}
    \item $ \delta_\text{diff} +A+\Delta$ is an upper bound on the minimally global robust bound of $N_1$ [in other words, $N_1$ is $ \delta_\text{diff} +A+\Delta$ globally robust with respect to the given perturbation].
    \item $ 2\cdot \delta_\text{diff} +A+\Delta$ is an upper bound on the minimally global robust bound of $N_2$. Proof:
    For every $x$ whose confidence is at least $2\cdot \delta_\text{diff} +A+\Delta$, by~\Cref{eq:diff}, $N_1$ classifies this input with confidence greater than $\delta_\text{diff} +A+\Delta$. By~\Cref{eq:ourproof}, for every $\epsilon'\in I_\epsilon$, we have $\mathcal{C}(f_P(x,\epsilon'),c',N_1)>\delta_\text{diff}$. By~\Cref{eq:diff}, we can infer, $\mathcal{C}(f_P(x,\epsilon'),c',N_2)>0$. 
  \end{itemize}
  To tighten $A$ for a smaller range of $\delta_\text{diff}$, we can add an upper bound on $\delta_\text{diff}$ denoted $u$ (a hyper-parameter):
  \begin{equation}\label{eq:ourproof}
 \max A \text{ subject to } \delta_\text{diff}>0\land \delta_\text{diff}<u\land \mathcal{C}(x,c,N_1) \geq \delta_\text{diff} + A\land \mathcal{C}(f_P(x,\epsilon'),c',N_1)\leq \delta_\text{diff}
 \end{equation}
 \paragraph{New Idea}
 In fact, we can compute upper and lower bounds on $\delta^\text{vhagar}_2$ by (1)~computing lower and upper bounds on  $\delta^\text{vhagar}_1$ for different confidence levels of the perturbations and (2)~after computing $\delta_\text{diff}$, looking for the suitable levels to infer bounds for $\delta^\text{vhagar}_2$.
 \begin{definition}[$\delta_p$-Perturbation Non-Robust Bound]\label{def:delta_u}
 Given a confidence level for the perturbation $\delta_p\in\mathbb{R}$, we define the $\delta_p$-perturbation non-robust bound as:  
\begin{equation}\label{eq:vagbound}
\max{\delta^\text{max}_{\delta_p}(N)}, \texttt{ subject to } \exists{x}\exists{\epsilon'}\in{I_\epsilon}: \mathcal{C}(x,c,N) \geq \delta^\text{max}_{\delta_p}(N) \land \mathcal{C}(f_P(x,\epsilon'),c,N)\leq \delta_p
\end{equation}
\end{definition}

% neta is making order

\paragraph{Relations between $\delta^{vaghar}(N_1)$and $\delta^{vaghar}(N_2)$):}
\begin{claim}\label{claim:delta_u_is_bigger_delta_v}
Given the definitions of $\delta^{vaghar}$ (Definition~\ref{def:vhagar}) and $\delta^\text{max}_{\delta_p}(N)$ (Definition~\ref{def:delta_u}), if $\delta_p \geq 0$, then $\delta^\text{max}_{\delta_p}(N) \geq \delta^{vaghar}$.
\end{claim}

\begin{proof}
Proof by construction. The definition of $\delta^{vaghar}$ is more restrictive than that of $\delta^\text{max}_{\delta_p}(N)$. In particular, any input $x$ that satisfies $\mathcal{C}(x, c, N) = \delta^{vaghar}$ also satisfies the constraint for $\delta^\text{max}_{\delta_p}(N)$, since $\mathcal{C}(f_P(x, \epsilon'), c, N) \leq 0 \leq \delta_p$. Therefore, the feasible set for $\delta^{vaghar}$ is a subset of that for $\delta^\text{max}_{\delta_p}(N)$, implying $\delta^\text{max}_{\delta_p}(N) \geq \delta^{vaghar}$.
\end{proof}

\begin{definition}[Gurobi optimization for vaghar]\label{def:delta_u_delta_l}
By the Gurobi optimization process we have an upper and lower bound for any optimization problem given, including vaghar for a network $N$: $\delta_l^{vaghar}(N) \leq \delta^{vaghar}(N) \leq \delta_u^{vaghar}(N)$ where $\delta_u^{vaghar}(N)-\delta_l^{vaghar}(N)\leq MIP_{Gap}$ where $MIP_{Gap}$ is a hyper parameter of Gurobi.
\end{definition}

\begin{claim}\label{claim:x2_eps_N1}
Let the following hold:
\begin{itemize}
    \item By Definition~\ref{def:vhagar}, for $\delta^{vaghar}(N_2)$, there exist $x^2_{vaghar}, \epsilon^2_{vaghar}$ such that
    \[
    \mathcal{C}(x^2_{vaghar}, c, N_2) = \delta^{vaghar}(N_2),\quad \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) \leq 0.
    \]
\end{itemize}
Then it follows that
\[
\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1) \leq \delta_p.
\]
\end{claim}

\begin{proof}
Assume $\delta_p = \delta_{\text{diff}}$ and that
\[
\forall x.\ |\mathcal{C}(x, c, N_2) - \mathcal{C}(x, c, N_1)| \leq \delta_p.
\]
This inequality also holds for $f_P(x^2_{vaghar}, \epsilon^2_{vaghar})$, so:
\[
|\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1) - \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2)| \leq \delta_p.
\]
Rewriting the above:
\begin{align*}
\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1) - \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) &\leq \delta_p, \\
-\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) &\leq \delta_p - \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1).
\end{align*}
By Definition~\ref{def:vhagar}, we know that
\[
\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) \leq 0 \quad \Rightarrow \quad -\mathcal{C}(f_P(\cdot), c, N_2) \geq 0,
\]
which implies:
\[
0 \leq \delta_p - \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1),
\]
and therefore:
\[
\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1) \leq \delta_p.
\]
\end{proof}


\begin{claim}\label{claim:x2_x1_delta_p}
Let the following hold:
\begin{itemize}
    \item By Definition~\ref{def:delta_u}, for $\delta^\text{max}_{\delta_p}(N_1)$, there exist $x^1_{\delta_p}, \epsilon^1_{\delta_p}$ such that
    \[
    \mathcal{C}(x^1_{\delta_p}, c, N_1) = \delta^\text{max}_{\delta_p}(N_1), \quad \mathcal{C}(f_P(x^1_{\delta_p}, \epsilon^1_{\delta_p}), c, N_1) \leq \delta_p.
    \]
    
    \item By Definition~\ref{def:vhagar}, for $\delta^{vaghar}(N_2)$, there exist $x^2_{vaghar}, \epsilon^2_{vaghar}$ such that
    \[
    \mathcal{C}(x^2_{vaghar}, c, N_2) = \delta^{vaghar}(N_2), \quad \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) \leq 0.
    \]
\end{itemize}
Then the following inequality holds:
\[
\mathcal{C}(x^2_{vaghar}, c, N_2) \leq \mathcal{C}(x^1_{\delta_p}, c, N_1).
\]
\end{claim}

\begin{proof}
Assume, for the sake of contradiction, that
\[
\mathcal{C}(x^2_{vaghar}, c, N_2) > \mathcal{C}(x^1_{\delta_p}, c, N_1).
\]
By Claim~\ref{claim:x2_eps_N1}, we know that
\[
\mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_1) \leq \delta_p.
\]
Therefore, $x^2_{vaghar}$ is a valid candidate for the optimization in Definition~\ref{def:delta_u}. However, its cost in $N_2$ exceeds that of $x^1_{\delta_p}$ in $N_1$, contradicting the optimality of $\delta^\text{max}_{\delta_p}(N_1)$ as the maximal achievable value under the constraint $\mathcal{C}(f_P(\cdot), c, N_1) \leq \delta_p$. This contradiction proves the claim.
\end{proof}


\begin{claim}\label{claim:delta_u1_and_delt2a}
Given 2 networks $N_1,N_2$ where $\forall x.\ |\mathcal{C}(x,c,N_2)-\mathcal{C}(x,c,N_1)|\leq \delta_p$ we can say $ \delta^\text{max}_{\delta_p}(N_1)+\delta_p \geq \delta_u^{vaghar}(N_2)$
\end{claim}
\begin{proof}
Reminder:
\begin{itemize}
\item By Definition~\ref{def:vhagar}, for $\delta^{vaghar}(N_2)$, there exist $x^2_{vaghar}, \epsilon^2_{vaghar}$ such that
    \[
    \mathcal{C}(x^2_{vaghar}, c, N_2) = \delta^{vaghar}(N_2), \quad \mathcal{C}(f_P(x^2_{vaghar}, \epsilon^2_{vaghar}), c, N_2) \leq 0.
    \]
\end{itemize}
so we can say:
$$\mathcal{C}(x^2_{vaghar},c,N_2)-\mathcal{C}(x^2_{vaghar},c,N_1)|\leq \delta_p$$
$$ \rightarrow \mathcal{C}(x^2_{vaghar},c,N_2) \leq \delta_p+\mathcal{C}(x^2_{vaghar},c,N_1)$$
According to ~\ref{claim:x2_x1_delta_p} we can say:
$$ \delta^{vaghar}(N_2)=\mathcal{C}(x^2_{vaghar},c,N_2) \leq \delta_p+\mathcal{C}(x^2_{vaghar},c,N_1) \leq \delta_p+ \mathcal{C}(x^1_{\delta_p}, c, N_1)=\delta_p+\delta^\text{max}_{\delta_p}(N_1)$$

According to ~\ref{def:delta_u_delta_l} we know $\delta^{vaghar}(N_2) \leq \delta^{vaghar}_u(N_2) \leq \delta^{vaghar}(N_2) + MIP_{Gap}$ where $MIP_{Gap}$ is a hyper parameter. Therefore we can choose $MIP_{Gap}$ small enough so the inequality $\delta^{vaghar}_u(N_2) \leq \delta_p+\delta^\text{max}_{\delta_p}(N_1)$ holds.

\end{proof}

\subparagraph{Finding a lower bound for $\delta^{vaghar}(N)$}
By applying Claim~\ref{claim:delta_u1_and_delt2a}, we can obtain upper bounds for $\delta_u^{vaghar}(N_1)$ and $\delta_u^{vaghar}(N_2)$ (as defined in Definition~\ref{def:delta_u_delta_l}). Consequently, this also provides upper bounds for $\delta^{vaghar}(N_1)$ and $\delta^{vaghar}(N_2)$, all by solving a single optimization problem as defined in Definition~\ref{def:delta_u} for network $N_1$. However we still need to find the value of $\delta_p=\delta_\text{diff}$ and a lower bound for $\delta_l^{vaghar}(N_1),\delta_l^{vaghar}(N_2)$. we will utilize the properties of anytime optimization process by Gurobi. For the lower bound, Gurobi looks for feasible solutions for our optimization problem, and then iteratively improves it as long there is no violation for the problems constraints. We find that gurobi mainly struggles to find the optimal upper bound, while gurobi finds feasible and close enough lower bound quickly. therefore, to find lower bounds for $\delta_l^{vaghar}(N_1),\delta_l^{vaghar}(N_2)$ can be find by setting a low TimeLimit when optimizing ~\ref{def:vhagar} for $N_1,N_2$.

\subparagraph{Finding $\delta_p=\delta_\text{diff}$}
we use bound prorogation to find $\delta_\text{diff}$:
$$I_{z_{m,k}^1,z_{m,k}^2}=[\Delta_{m,k}^l,\Delta_{m,k}^u],\ \text{max}\{z_{m,k}^1,z_{m,k}^2\}\leq{\Delta_{m,k}^u},\ \text{min}\{z_{m,k}^1,z_{m,k}^2\}\geq{\Delta_{m,k}^l}$$
$$
I_{z_{m,k}^1,z_{m,k}^2}=I_{b_{m,k}^1,b_{m,k}^2}+\sum_{k'=1}^{k_{m-1}}{w_{m,k,k'}\cdot{I_{z_{m-1,k}^1,z_{m-1,k}^2}}+I_{w_{m,k,k'}^1,w_{m,k,k'}^2}\cdot{z_{m-1,k'}^1+I_{z_{m-1,k'}^1,z_{m-1,k'}^2}} }
$$
And overall we can say:

$$\delta_\text{diff}\leq{\text{max}\{|\Delta_{L,c}^u-\text{max}_{c'\ne{c}}{\Delta_{L,c'}^l}|,|\Delta_{L,c}^l-\text{max}_{c'\ne{c}}{\Delta_{L,c'}^u}|\}}$$
Due to its efficiency, this process is well-suited for application to larger-scale networks in practice.   

 
 \paragraph{Combining all of the sub-optimization problems:}
So far, we have presented several methods for obtaining upper and lower bounds on $\delta^{vaghar}(N_1)$ and $\delta^{vaghar}(N_2)$ (see Claims~\ref{claim:delta_u_is_bigger_delta_v},~\ref{claim:delta_u1_and_delt2a}). While these bounds are generally looser than those obtained by directly optimizing the \texttt{vaghar} formulation for $N_1$ and $N_2$, they offer a more efficient and scalable alternative—particularly suitable for larger neural networks:
  $$ t_{\delta^{vaghar}(N_1)} + t_{\delta^{vaghar}(N_1)} \geq t_{{\delta_1}_u} + t_{{\delta_1}_l} + t_{{\delta_2}_l} + t_{\delta_{\text{diff}}}$$
 where:
 $$ {{\delta_1}_l} \leq \delta_1 \leq {{\delta_1}_u} $$
  $$ {{\delta_2}_l} \leq \delta_2 \leq {{\delta_1}_u}+{\delta_{\text{diff}}} $$
  
\begin{algorithm}
\caption{Compute Robustness Bounds($N_1$, $N_2$, $D$, $f_P$, $I_\epsilon$, $c$)}
\begin{algorithmic}[1]
\Require 2 classifiers $N_1$ and $N_2$, a dataset $D$, a perturbation $f_P$, its range $I_\epsilon$, a class $c$
\Ensure Bounds for $\delta^{vaghar}(N_1)$ and $\delta^{vaghar}(N_2)$.
%\Comment{ Compute $\delta_\text{diff}^c$}
\State $\delta^{vaghar}_{l}(N_1)$ = \text{VAGHaR($N_1$,$D$, $f_P$, $I_\epsilon$, $c$, $TimeLimit=120_\text{sec}$)}
\State $\delta^{vaghar}_{l}(N_2)$ = \text{VAGHaR($N_2$,$D$, $f_P$, $I_\epsilon$, $c$, $TimeLimit=120_\text{sec}$)}
\State $N_1^\#$ = \text{Define\_Hyper\_Network($\{N_1\}$)}
\State $I$ = \text{Compute\_Difference\_Intervals($N_1^\#$,$N_2$)}
\State $\delta_\text{diff}^c$ = $\text{max}\{ |I[c]^u-\text{max}_{i\ne{c}}{I[i]^l}|,|I[c]^l-\text{max}_{i\ne{c}}{I[i]^u}| \}$
\State $\phi_\text{in}$ = \text{Compute\_Input\_Perturbation\_Dependencies($N_1$, $f_P$, $I_\epsilon$)}
\State $\phi_\text(dep)$ = \text{Compute\_dependency\_constraints($N_1$, $f_P$, $I_\epsilon$, $\phi_\text{in}$)}
\State $\delta^\text{HA}_\text{c}$, $\text{H}_{N_1}$, $\text{H}_{N_1^p}$ = \text{Compute\_lower\_bound\_and\_hints($N_1$, $D$, $c$, $f_P$, $I_\epsilon$)}
\State optimize($\max_{x,\epsilon'}\delta_{\delta_\text{diff}^c}^\text{max}$ subject to: 
$\epsilon'\in I_\epsilon,\ \phi_\text{in},\ \phi_\text{dep},\ \delta_{\delta_\text{diff}^c}^\text{max} \geq \delta^\text{HA}_\text{c},$\\
\hspace*{2em} $\mathcal{C}(x,c,N_1)=\delta_{\delta_\text{diff}^c},\ 
\mathcal{C}(f_P(x,\epsilon'),c,N_1) \leq \delta_\text{diff}^c$)

\State \Return \text{[$\delta^{vaghar}_{l}(N_1)$,$\delta_{\delta_\text{diff}^c}$], [$\delta^{vaghar}_{l}(N_2)$,$\delta_{\delta_\text{diff}^c}-\delta_\text{diff}^c$]}
\end{algorithmic}
\end{algorithm}
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\paragraph{Formulation:}
\subparagraph{$\delta_{\delta_\text{diff}^c}^\text{max}$}
$$ \text{max}\ \delta_{\delta_\text{diff}^c}^\text{max}\ \text{subject to} $$
\begin{align*}
\tag{a}\quad & x\in{[0,1]^d},\ \forall{k}:\ z_{0,k}^1=x_k,\ {z_{0,k}^{1,p}}=x_k\\
\tag{b}\quad & \forall{c'\ne{c}}:\ {z_{L,c}^1}-{z_{L,c'}^1}\geq\delta_{\delta_\text{diff}^c}^\text{max},\   \forall{c'\ne{c}}:\ {z_{L,c}^{1,p}}-{z_{L,c'}^{1,p}}\leq{\delta_{\text{diff}}^c+M\cdot{(1-\alpha_{c'})}};\ \sum_{c'\ne{c}}{\alpha}\geq{1}\\
\tag{c}\quad &  \forall{m>0,k}:\ \hat{z}_{m,k}^1=b_{m,k}^1+\sum_{k'=1}^{k_{m-1}}{w_{m,k,k'}^1\cdot{z_{m-1,k'}^1}},\ \hat{z}_{m,k}^{1,p}=b_{m,k}^{1,p}+\sum_{k'=1}^{k_{m-1}}{w_{m,k,k'}^{1,p}\cdot{z_{m-1,k'}^{1,p}}}  \\
\tag{d}\quad & z_{m,k}^{1}\geq{0},\ z_{m,k}^{1}\geq{\hat{z}_{m,k}^{1}},\ z_{m,k}^{1}\leq{u_{m,k}^{1}\cdot{a_{m,k}^{1}}},\ z_{m,k}^{1}\leq{\hat{z}_{m,k}^{1}-l_{m,k}^{1}\cdot{(1-a_{m,k}^{1})}}\\ 
\quad & z_{m,k}^{1,p}\geq{0},\ z_{m,k}^{1,p}\geq{\hat{z}_{m,k}^{1,p}},\ z_{m,k}^{1,p}\leq{u_{m,k}^{1,p}\cdot{a_{m,k}^{1,p}}},\ z_{m,k}^{1,p}\leq{\hat{z}_{m,k}^{1,p}-l_{m,k}^{1,p}\cdot{(1-a_{m,k}^{1,p})}} 
    \\
\end{align*}


\paragraph{Adversarial training - fine tuning idea}
when calculating the upper bound for classifiers $N_1,N_2,N_3...$ we have a set of inputs $\{x_1,x_2,...\}X$ the satisfy $\forall{i}:\ \mathcal{C}(N_i,x_i,c) \geq \delta_i\ \text{and}\ \mathcal{C}(N_i,x_i,c) \leq \text{diff}$.
\begin{itemize}
\item find $x_i^{vaghar}$ using X set (use GD).
\item try to locate the new set of $X^{vaghar}$ on a grid - see if the are close to one another using some "dist" function. maybe using a certain norm they capture some input space?
\item then we can take the main model (still need to choose which to consider the main one - maybe create a new model based on the classifiers $\{N_1,N_2,...\}$
\end{itemize}
%compute the minimal class confidence $\delta_1$ and $\delta_2$, where $\forall{x}\forall{\epsilon'}\in{I_{\epsilon}}$ it holds that:
\begin{comment}
$$\max{\delta_1^{opt}}, \texttt{ subject to } \exists{x}\exists{\epsilon'}\in{I_\epsilon}: \mathcal{C}(x,c,N_1) \geq \delta_1^{opt} \rightarrow \mathcal{C}(f_P(x,\epsilon'),c',N_1)\leq \frac{\delta_1^{opt}}{10} $$
after optimizing $\delta_1^{opt}$ we optimize the following:
$$\max{\delta_2^{opt}}, \texttt{ subject to }  \exists{x}:  \mathcal{C}(x,c,N_2) \geq \delta_2^{opt} \rightarrow \mathcal{C}(x,c,N_1)\leq \delta_1^{opt}$$
Which means, we look for input $x$ such that $N_2$ would classify $x$ correctly, but $N_1$ wont be able to guarantee that $f_P(x,\epsilon')$ would be classified correctly, and so is $N_2$. 
\\
Note that We demand $\frac{\delta_1}{10}$ as an upper bound instead of $0$ since we want to maximize $\delta_2^{opt}$ for networks with larger confidence difference in the future while maintaining the global robustness property, by making sure that $\delta_1^{opt} \geq \delta^{vhagar}_1$ and $\delta_2^{opt} \geq \delta^{vhagar}_2$.

\input{proofNewProblemDefinition.tex}

Formally, given two classifiers $F_1,F_2: \mathbb{R}^{n \times m} \rightarrow {\mathbb{R}}^{|C|}$, a class $c\in{C}$, a perturbation $P$ and its range $I_\epsilon$, our goal is to compute the minimal class confidence $\delta$, where $\forall{x}\forall{\epsilon'}\in{I_{\epsilon}}$ it holds that:
\begin{enumerate}[nosep,nolistsep]
    \item $\mathcal{C}(x,c',F_1) \geq \delta$ %\Dana{what is D? should it be $D_1$?} NETA - You are right. there was a mistake. I fixed it.
    \item $\mathcal{C}(x,c',F_2) > 0$
    \item $\mathcal{C}(f_P(x,\epsilon'),c',F_1)> 0$
    \item $\mathcal{C}(f_P(x,\epsilon'),c',F_2> 0$
\end{enumerate} 
To put it simply, we aim for the minimal confidence score of classifier $F_1$ for class $c'$ such that another classifier $F_2$ also predicts the input $x$ as belonging to class $c'$, and both $F_1$ and $F_2$ predict correctly the perturbed input $(f_P(x,\epsilon')$ as $c'$. However, solving this problem is difficult for existing solvers, due to the for all operators. Instead, we solve the dual problem, i.e.,  the maximal class confidence $\delta'$, where there exists an input $x$ and a perturbation amount ${\epsilon'}\in{I_\epsilon}$ satisfying:%\Dana{please explain in words this definition}
\begin{enumerate}[nosep,nolistsep]
    \item $\mathcal{C}(x,c',F_1) \geq \delta'$ %\Dana{what is D? should it be $D_1$?} NETA - You are right. there was a mistake. I fixed it.
    \item $\mathcal{C}(x,c',F_2) > 0$
    \item $\mathcal{C}(f_P(x,\epsilon'),c',F_1)\leq 0$
    \item $\mathcal{C}(f_P(x,\epsilon'),c',F_2)\leq 0$
\end{enumerate} 
The goal is to maximize the confidence score of classifier $F_1$ for a specific class $c'$ such that classifier $F_2$ also predicts the input $x$ as belonging to class $c'$. At the same time, classifiers $F_1$ and $F_2$ are unable to correctly classify the input $f_P(x,\epsilon')$, where $f_P(x,\epsilon')$ is $x$ after it has been altered by the perturbation amount $\epsilon'$. In simple terms, the objective is to simultaneously align the outputs of the two classifiers on the original input while disrupting their ability to correctly classify the perturbed version. 

\end{comment}

\bibliographystyle{plain}   % or IEEEtran, unsrt, abbrv, etc.
\bibliography{bibliography}
\end{document} 
   % bibliography.bib must exist in the same folder
