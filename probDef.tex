%! Author = julianmour
%! Date = 01/05/2023

\section{Problem Definition}

\sloppy
\paragraph{Multi-label classifier}
An image multi-label classifier $D$ is a function mapping a two-dimensional image $x\in \mathbb{R}^{n \times m}$ to a score vector over the possible set of classes $C=\{1,\ldots,c\}$, that is:
$D: \mathbb{R}^{n \times m} \rightarrow {\mathbb{R}}^{|C|}$.
This research would focus on two multi-label classifiers of the same task, with similar architectures.


\paragraph{Global Robustness of a sSingle Network}
Given a perturbation $P$ and its range $I_\epsilon$, a naive approach for global robustness is:
$\forall{x}\forall{\epsilon'}\in{I_\epsilon}$  argmax($D(x)$) = argmax($f_P(x,\epsilon')$).
However, this property is problematic because some inputs $x$ are too close to the classifier's decision boundaries and violate this property ~\cite{DECISIONBOUND}, and as a result we are not able to satisfy it for non-trivial classifier. Thus, this study focuses on inputs whose networks' confidence in the classification is high enough ~\cite{VHAGAR}:

Given a classifier $D$, an input $x$ and a class $c'\in{C}$, the class confidence of $D$ in $c'$ is:
$\mathcal{C}(x,c',D)=D(x)_{c'}-max_{c''\ne c'}(D(x)_{c''})$.\\
For a single network, ~\cite{VHAGAR} defined the property $\delta-Global Robustness$ as follows:\\
Given a classifier $D$, an input $x$ and a class $c'\in{C}$, a perturbation $P$, a range $I_\epsilon$ and a class confidence $\delta>0$, the classifier $D$ is $\delta$-globally robust for $c'$ under $(P,I_\epsilon)$ if:\\
$\forall{x}\forall{\epsilon'}\in{I_\epsilon}$ $\mathcal{C}(x,c',D) \geq \delta \rightarrow$ argmax($D(x)$) = argmax($f_P(x,\epsilon')$).

Intuitively, the classifier is robust for any confidence higher or equal to the minimal $delta$. However, this definition cannot be solved via MIP solvers. Therefore, we need to adjust the definition to MIP solvers and consider the dual problem: computing the maximal globally robust bound. This way we would look for the maximal $\delta$ that violates the constraint. Overall, for a single classifier the property we would like to evaluate is:

$\max{\delta}$ subject to $\exists{x}\exists{\epsilon'}\in{I_\epsilon}$ $\mathcal{C}(x,c',D) \geq \delta \rightarrow \mathcal{C}(f_P(x,\epsilon'),c',D)\leq 0$.


\paragraph{Problem definition} Given two classifiers $F_1,F_2: \mathbb{R}^{n \times m} \rightarrow {\mathbb{R}}^{|C|}$ with similar architecture, a class $c\in{C}$, a perturbation $P$ and its range $I_\epsilon$ the goal is to compute the upper and lower bounds for the maximal $\delta$, where $\exists{x}\exists{\epsilon'}\in{I_\epsilon}$ satisfying:

\begin{enumerate}[nosep,nolistsep]
    \item $\mathcal{C}_{F_1}(x,c',D) \geq \delta$
    \item $\mathcal{C}_{F_2}(x,c',D) > 0$
    \item $\mathcal{C}_{F_1}(f_P(x,\epsilon'),c',D)\leq 0$
    \item $\mathcal{C}_{F_2}(f_P(x,\epsilon'),c',D)\leq 0$
\end{enumerate}

%\begin{gather*}
%    \varepsilon_x^*  = argmax_{\varepsilon_x \in RLN_x^\varepsilon} \{w_x \times \varepsilon_x^T\}\\
%%    I_x = \{x' \mid \forall l_d^x\in L_x: \forall (i,j)\in l_d^x: x'_{i,j} \in [x_{i,j}-\varepsilon_d^x, x_{i,j}+\varepsilon_d^x]\}\\
%\end{gather*}
%\Dana{fix the above so it will be like in Marvel}
%\Dana{comment 1: don't put \$ in gather env}
%\Dana{comment 2: we don't build programs, but rather algorithms}
%\Dana{comment 3: in this section, we aim to compute maximal neighborhoods, not design an algorithm, this will come in the nxt section} 